\documentclass[hidelinks, 12pt]{report}
\usepackage{graphicx}
\usepackage{marginnote}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{geometry}
\usepackage[document]{ragged2e}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{fancyhdr}
\usepackage{float}
%\usepackage{floatrow}
\usepackage{caption}
%\usepackage{calc}
\usepackage{chngcntr}
\usepackage[caption = false]{subfig}
\usepackage[subfigure]{tocloft}
\newlength{\mylen}
\usepackage[font=footnotesize,labelfont=bf]{caption}
%\usepackage{times}
\usepackage[table]{xcolor}
\usepackage[intoc]{nomencl}
\usepackage{setspace}
\usepackage{tocloft}

%\usepackage{nomencl}
%\let\abbrev\nomenclature
%\makenomenclature 
%\newcommand{\Abkuerzung}{
%\printnomenclature
%\newpage
%}


\usepackage{array}
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=green,      
    urlcolor=cyan,
    citecolor=magenta,
}
\urlstyle{same}
\usepackage{bookmark}
\renewcommand{\cftfigpresnum}{\figurename\enspace}
\renewcommand{\cftfigaftersnum}{:}
\settowidth{\mylen}{\cftfigaftersnum\cftfigpresnum}
\addtolength{\cftfignumwidth}{\mylen}
\counterwithin{figure}{section}

\renewcommand{\cfttabpresnum}{\tablename\enspace}
\renewcommand{\cfttabaftersnum}{:}
\settowidth{\mylen}{\cfttabaftersnum\cftfigpresnum}
\addtolength{\cfttabnumwidth}{\mylen}
\counterwithin{table}{section}

\renewcommand{\labelenumi}{(\roman{enumi})}

\geometry{margin=1in}

\usepackage{titlesec}
\titleformat{\chapter}[display]
{\normalfont %
    \Huge % %change this size to your needs for the first line
    \bfseries}{\chaptertitlename\ \thechapter}{20pt}{%
    \huge} %change this size to your needs for the second line
 


\fancyhf{}
\fancyhead[LE,LO]{\footnotesize{}}
\fancyhead[RE,RO]{\footnotesize{Underwater Image Enhancement}}
\fancyfoot[LE,LO]{\footnotesize{Govt. Model Engineering College}}
\fancyfoot[RE,RO]{\footnotesize\thepage}
\renewcommand{\headrulewidth}{1pt}
\renewcommand{\footrulewidth}{1pt}
%\renewcommand{\familydefault}{\rmdefault}
\newcommand{\Rnum}[1]{\uppercase\expandafter{\romannumeral#1}}
\newcommand{\rnum}[1]{\romannumeral#1\relax}
%\setcounter{secnumdepth}{4}
%\setcounter{tocdepth}{4}

\begin{document}
\pagenumbering{none}
\centering
\section*{\centering{Bonafide Certificate}}
\vspace{1cm}
\includegraphics[height=3cm,width=3cm]{logo}

\begin{center}
MODEL ENGINEERING COLLEGE\\
\vspace{0.5cm}
THRIKKAKARA, KOCHI-21\\
\vspace{0.5cm}
DEPARTMENT OF ELECTRONICS AND COMMUNICATION \\
\vspace{0.5cm}
APJ ABDUL KALAM TECHNOLOGICAL UNIVERSITY \\
\vspace{1cm}
\textit{Bonafide Certificate}
\\This is to Certify that the Seminar Report entitled\\
\vspace{0.5cm}
\textbf{Colour Balance and Fusion for Underwater Image Enhancement} 
\\
\vspace{0.5cm}
Submitted by\\
\vspace{0.2cm}
P H Aju\\
\vspace{0.2cm}
is a bonafide account of her work done under our supervision. \\
\end{center}

\vspace{2cm}
\begin{minipage}[t]{10cm}
\flushleft \textbf{Seminar Co-ordinator}\\
Prof. Rajesh Mohan R\\
Associate Professor\\
Dept. of Electronics and\\
Communication Engineering
\end{minipage}
\vspace{2cm}
\begin{minipage}[t]{5cm}
\flushleft \textbf{Seminar Guide}\\
Prof. Nima Dharmapal\\
Assistant Professor\\
Dept. of Electronics and\\
Communication Engineering
\end{minipage}
%\begin{minipage}[t]{5cm}
%\flushleft Head of Department\\
%Mr. Pradeep M\\
%Associate Professor\\
%\end{minipage}

%\addcontentsline{toc}{chapter}{Abstract}
\chapter*{Abstract}
\justify
\textit{
Underwater environment offers many rare attractions for photography. Underwater imaging has also been an important source of interest in different branches of technology and scientific research. But underwater images suffer from poor visibility resulting from the attenuation of the propagated light. Underwater image dehazing techniques are present but they require complex hardware to capture multiple data of underwater environment. However, these issues can be avoided by using 'Colour Balance and Fusion Technique'This method is a single image approach that does not require specialized hardware or knowledge about the underwater conditions or scene structure. It builds on the blending of two images that are directly derived from a color compensated and white-balanced version of the original degraded image. The two images to fusion, as well as their associated weight maps, are defined to promote the transfer of edges and color contrast to the output image. To avoid that the sharp weight map transitions create artifacts in the low frequency components of the reconstructed image, a multiscale fusion strategy is adopted. Extensive qualitative and quantitative evaluation reveals that our enhanced images and videos are characterized by better exposedness of the dark regions, improved global contrast, and edges sharpness. This algorithm is reasonably independent of the camera settings, and improves the accuracy of several image processing applications, such as image segmentation and keypoint matching.}\\

\textit{\textbf{keyword}}- 
Underwater Optical Model, Red Channel Equalisation, Gray World, Multi-Scale Fusion, Gaussian Pyramid.
%\end{keyword}
%\sep%

\pagebreak
\setcounter{page}{1}
\pagenumbering{roman}
\justify
%\onehalfspacing
\begin{spacing}{0.8}
\renewcommand{\contentsname}{Table of Contents}
\pdfbookmark{\contentsname}{Table of Contents}
\tableofcontents
\end{spacing}
\pagebreak
%line spacing
\addcontentsline{toc}{chapter}{List of Figures}
\listoffigures 
\pagebreak
\renewcommand{\nomname}{List of Abbreviations}
\addcontentsline{toc}{chapter}{List of Abbreviations}
\printnomenclature
\pagebreak
%\addcontentsline{toc}{chapter}{List of Tables}
%\listoftables
%\pagebreak

\section*{List of Abbreviations}
\begin{flushleft}
DCP -  Dark Channel Prior\\ 
\vspace{0.5cm}
UDCP - Underwater Dark Channel Prior\\
\vspace{0.5cm}
QDs - Quantum Dots\\
\vspace{0.5cm}
MBE - Molecular Beam Epitaxy\\
\vspace{0.5cm}
MOCVD - Metal Organic Chemical Vapour Deposition\\
\vspace{0.5cm}
IB - Intermediate Band\\
\vspace{0.5cm}
QFL - Quasi Fermi Level\\
\vspace{0.5cm}
VB - Valence Band\\
\vspace{0.5cm}
CB - Conduction Band\\ 
\vspace{0.5cm}
IBSC - Intermediate Band Solar Cell\\
\vspace{0.5cm}
MEG - Multiple Exciton Generation\\
\vspace{0.5cm}
QDSC - Quantum Dot Solar Cell\\
\vspace{0.5cm}
QD- IBSC - Quantum Dot Intermediate Band Solar Cell\\
\vspace{0.5cm}
SRL - Strain Relief Layer\\
\end{flushleft}
\pagebreak

\addcontentsline{toc}{chapter}{Acknowledgement}
\section*{Acknowledgement}
\justify
On the recollection of so many great favors and blessings, I offer my sincere thanks to the Almighty, the Creator and Preserver.\\
%\vspace{1cm}

I express my heartfelt gratitude to \textbf{Prof. Dr. V P Devassia}, Principal, Govt. Model Engineering College, Thrikkakara for providing me with excellent library facilities. \\
I sincerely thank Prof. Nima Dharmapal, Assistant Professor of Department of Electronics and Communication Engineering, for her timely advice and suggestions.\\

%I am thankful to my seminar coordinator \textbf{Prof. Rajesh Mohan R}, Associate Professor, Department of Electronics and Communication Engineering for the full-fledged support and guidance. I would like to express my sincere gratitude to \textbf{Dr. Jobymol Jacob}, Professor, Department of Electronics and Communication Engineering, who has always motivated me and helped me to do everything in a better way.  \\
%\vspace{1cm}

Last but not the least I am thankful to one and all of the Department of Electronics and Communication Engineering and the whole library staff for their co-operation and active involvement.
I also thank my colleagues for their support.
\hbox{} \newpage 
\pagenumbering{arabic} 
\pagestyle{fancy}
\chapter{Introduction}
\justify
Underwater environment offers many rare attractions such as marine animals and fishes, amazing landscape, and mysterious shipwrecks. Besides underwater photography, underwater imaging has also been an important source of interest in different branches of technology and scientific research, such as inspection of underwater infrastructures and cables, detection of man made objects, control of underwater vehicles, marine biology research, and archeology. Different from common images, underwater images suffer from poor visibility resulting from the attenuation of the propagated light, mainly due to absorption and scattering effects. The absorption substantially reduces the light energy, while the scattering causes changes in the light propagation direction. They result in foggy appearance and contrast degradation, making distant objects misty. Practically, in common sea water images, the objects at a distance of more than 10 meters are almost unperceivable, and the colors are faded because their composing wavelengths are cut according to the water depth. There have been several attempts to restore and enhance the visibility of such degraded images. Since the deterioration of underwater scenes results from the combination of multiplicative and additive processes traditional enhancing techniques such as gamma correction, histogram equalization appear to be strongly limited for such a task. In the previous works, the problem has been tackled by tailored acquisition strategies using multiple images, specialized hardware or polarization filters. Despite of their valuable achievements, these strategies suffer from a number of issues that reduce their practical applicability. This is a novel approach to remove the haze in underwater images based on a single image captured with a conventional camera. Our approach builds on the fusion of multiple inputs, but derives the two inputs to combine by correcting the contrast and by sharpening a white-balanced version of a single native input image. The white balancing stage aims at removing the color cast induced by underwater light scattering, so as to produce a natural appearance of the sub-sea images. The multi-scale implementation of the fusion process results in an artifact-free blending.
\begin{figure}[H]
\centering
\includegraphics[width=15cm,height=5cm]{Block.png}
\caption[Method Overview]{Method Overview}
\label{Method Overview}
\end{figure}
\chapter{Background Knowledge and Previous Art}
\section{Light Propogation in Underwater Environment}
\justify
For an ideal transmission medium the received light is influenced mainly by the properties of the target objects and the camera lens characteristics. This is not the case underwater. First, the amount of light available under water, depends on several factors. The interaction between the sun light and the sea surface is affected by the time of the day (which influences the light incidence angle), and by the shape of
the interface between air and water (rough vs. calm sea). The diving location also directly impacts the available light, due to a location-specific color cast: deeper seas and oceans induce green and blue casts, tropical waters appear cyan, while protected reefs are characterized by high visibility. In addition to the variable amount of light available underwater, the density of particles that the light has to go through
is several hundreds of times denser in seawater than in normal atmosphere. As a consequence, sub-sea water absorbs gradually different wavelengths of light. Red, which corresponds to the longest wavelength, is the first to be absorbed (10-15 ft), followed by orange (20-25 ft), and yellow (35-45 ft). Pictures taken at 5 ft depth will have a noticeable loss of red. Further-more, the refractive index of water makes judging distances difficult. As a result, underwater objects can appear 25\% larger than they really are. The comprehensive studies have shown that the total irradiance incident on a generic point of the image plane has three main components in underwater mediums: direct component, forward scattering and back scattering. The direct component is the component of light reflected directly by the target object onto the image plane. At each image coordinate x the direct component is expressed as:
\begin{equation}
E_D(x)=J(x)e^{-\eta d(x)}=J(x)t(x)
\end{equation}
where $J(x)$ is the radiance of the object, $d(x)$ is the distance between the observer and the object, and $\eta$ is the attenuation coefficient. The exponential term $e^{−ηd(x)}$ is also known as the transmission $t(x)$ through the underwater medium.\\
Besides the absorption, the floating particles existing in the underwater mediums also cause the deviation (scattering) of the incident rays of light. Forward-scattering results from a random deviation of a light ray on its way to the camera lens. It has been determined experimentally that its impact can be approximated by the convolution between the direct attenuated component, with a point spread function that depends on the distance between the image plane and the object. Back-scattering is due to the artificial light (e.g. flash) that hits the water particles, and is reflected back to the camera. Back-scattering acts like a glaring veil superimposed on the object. The influence of this component may be reduced significantly by simply changing the position and angle of the artificial light source so that most of the reflected particle light do not reach the camera. However, in many practical cases, back-scattering remains the principal source of contrast loss and color shifting in underwater images. Mathematically, it is often expressed as:
\begin{equation}
E_BS(x)=B_{\infty}(x)(1-e^{-\eta d(x)})
\end{equation}
where $B_{\infty}(x)$ is a color vector known as the \textit{back-scattered} light.\\
Ignoring the forward scattering component, the simplified underwater optical model thus becomes:
\begin{equation}
I(x)=J(x)e^{-\eta d(x)}+B_{\infty}(x)(1-e^{-\eta d(x)})
\end{equation}
This simplified underwater camera model is used to characterize the propagation of light in the atmosphere. It however does not reflect the fact that the attenuation coefficient strongly depends on the light wavelength, and thus the color, in underwater environments. Therefore, as discussed in the next section, a straightforward extension of outdoor dehazing approaches performs poorly at great depth, in presence of non-uniform artificial illumination and selective absorption of colors. It is also why this approach does not resort to an explicit inversion of the light propagation model.
\section{Related Works}
\justify
The existing underwater dehazing techniques can be grouped in several classes. 
\begin{itemize}
\item{Using specialized hardware - For instance, the divergent-beam underwater Lidar imaging (UWLI) system uses an optical/laser-sensing technique to capture turbid underwater images. Unfortunately, these complex acquisition systems are very expensive, and power consuming.}
\item{Polarization-based methods - These approaches use several images of the same scene captured with different degrees of polarization, as obtained by rotating a polarizing filter fixed to the camera. While being effective in recovering distant regions, the polarization techniques are not applicable to video acquisition, and are therefore of limited help when dealing with dynamic scenes.}
\item{Multiple images - A rough approximation of the scene model is created with huge amount of data. Since this additional information (images and depth approximation) is generally not available, these methods are impractical for common users.}
\item{Exploiting the similarities between light propagation in fog and under water - Several single image dehazing techniques have been introduced to restore images of outdoor foggy scenes. These dehazing techniques reconstruct the intrinsic brightness. Several works have shown that it can be used in heterogeneous lightning conditions and with heterogeneous extinction coefficient as long as the model parameters are estimated locally. However, the underwater imaging is even more challenging, due to the fact that the extinction resulting from scattering depends on the light wavelength, i.e. on the color component.}
\end{itemize}
Recently, several algorithms that specifically restore underwater images based on Dark Channel Prior (DCP), have been introduced. The DCP has initially been proposed for outdoor scenes dehazing. It assumes that the radiance of an object in a natural scene is small in at least one of the color component, and consequently defines regions of small transmission as the ones with large minimal value of colors. In the underwater context, many approaches were considered:
\begin{itemize}
\item{Segmenting foreground and background regions based on DCP, and uses this information to remove the haze and color variations based on color compensation.}
\item{Assuming that the predominant source of visual information under the water lies in the blue and green color channels. Their Underwater Dark Channel Prior (UDCP) has been shown to estimate better the transmission of underwater scenes than the conventional DCP.}
\item{Observations that the red component reciprocal increases with the distance to the camera introduced the Red Channel prior to recover colors associated with short wavelengths in underwater.}
\item{Designing a hierarchical rank based method, using a set of features to find those image regions that are the most haze-opaque, thereby refining the back-scattered light estimation, which in turns improves the light transmission model inversion.}
\item{Employing color lines to estimate the ambient light and implement a variant of the DCP to estimate the transmission.}
\item{Bilateral filter is considered to remove highlighted regions before ambient light estimation, and another locally adaptive filter is considered to refine the transmission.}
\item{Extending colour lines to increase the resolution of its descattered and color-corrected output. This extension builds on super-resolution from transformed self-exemplars to derive two high-resolution (HR) images, respectively from the output derived in and from a denoised/descattered version of this output. A fusion-based strategy is then considered to blend those two intermediate HR images. This fusion aims at preserving the edges and detailed structures of the noisy HR image, while taking advantage of the reduced noise and scatter in the second HR image. It however does not impact the rendering of color obtained with.}
\end{itemize}
\chapter{Underwater White Balance}
\justify
This image enhancement approach adopts a two step strategy, combining white balancing and image fusion, to improve underwater images without resorting to the explicit inversion of the optical model. Here, white balancing aims at compensating for the color cast caused by the selective absorption of colors with depth, while image fusion is considered to enhance the edges and details of the scene, to mitigate the loss of contrast resulting from back-scattering.\\ White-balancing aims at improving the image aspect, primarily by removing the undesired color castings due to various illumination or medium attenuation properties. In underwater, the perception of color is highly correlated with the depth, and an important problem is the green-bluish appearance that needs to be rectified. As the light penetrates the water, the attenuation process affects selectively the wavelength spectrum, thus affecting the intensity and the appearance of a colored surface. Since the scattering attenuates more the long wavelengths than the short ones, the color perception is affected as we go down in deeper water. In practice, the attenuation and the loss of color also depends on the total distance between the observer and the scene. Large spectrum of existing white balancing methods were considered, a number of solutions were identified that are both effective and suited to our problem.\\ The following are those approaches which inspired in the derivation of this novel approach proposed for underwater scenes.
\begin{itemize}
\item{Gray world algorithm assumes that the average reflectance in the scene is achromatic. Hence, the illuminant color distribution is simply estimated by averaging each channel independently.}
\item{The Max RGB assumes that the maximum response in each channel is caused by a white patch, and consequently estimates the color of the light source by employing the maximum response of the different color channels.}
\item{The ‘Shades-of-Grey’ method, Max-RGB and Gray-World are two instantiations of the Minkowski $p$-norm applied to the native pixels,  espectively with $p=\infty$ and $p=1$, and propose to extend the process to arbitrary $p$ values. The best results are obtained for $p=6$.}
\item{The Grey-Edge hypothesis further extends this Minkowski norm framework. It assumes the average edge difference in a scene to be achromatic, and computes the scene illumination color by applying the Minkowski p-norm on the derivative structure of image channels, and not on the zero-order pixel structure, as done in Shades of Grey. Despite of its computational simplicity, this approach has been shown to obtain comparable results than state-of-the-art color constancy methods, such as the recent method that relies on natural image statistics.}
\end{itemize}
\begin{figure}[H]
\centering
\includegraphics[width=15cm,height=5cm]{White.png}
\caption[Underwater White Balance]{Underwater White Balance}
\label{Underwater White Balance}
\end{figure}
When focusing on underwater scenes, the well-known Gray-World algorithm achieves good visual performance for reasonably distorted underwater scenes. However, a deeper investigation dealing with extremely deteriorated underwater scenes revealed that most traditional methods perform poorly. They fail to remove the color shift, and generally look bluish. The methods that best remove the bluish tone is the Grey World, but we observe that this method suffers from severe red artifacts. Those artifacts are due to a very small mean value for the red channel, leading to an overcompensation of this channel in locations where red is present (because Gray world devides each channel by its mean value).\\
To compensate for the loss of red channel, the following observations/principles were proposed:
\begin{itemize}
\item{The green channel is relatively well preserved under water, compared to the red and blue ones. Light with a long wavelength, i.e. the red light, is indeed lost first when traveling in clear water.}
\item{The green channel is the one that contains opponent color information compared to the red channel, and it is thus especially important to compensate for the stronger attenuation induced on red, compared to green. Therefore, to compensate the red attenuation, a fraction of the green channel is added to red. The information of the green channel alone allows better recovery of the entire color spectrum while maintaining a natural appearance of the background(water regions) than adding both a fraction of green and blue to the red.}
\item{The compensation should be proportional to the difference between the mean green and the mean red values because, under the Gray world assumption (all channels have the same mean value before attenuation), this difference reflects the disparity/unbalance between red and green attenuation.}
\item{To avoid saturation of the red channel during the Gray World step that follows the red loss compensation, the enhancement of red should primarily affect the pixels with small red channel values, and should not change pixels that already include a significant red component. In other words, the green channel information should not be transferred in regions where the information of the red channel is still significant. Thereby, the reddish appearance introduced by the Gray-World algorithm in the over-exposed regions should be avoided. Basically, the compensation of the red channel has to be performed only in those regions that are highly attenuated. This argument follows the statement, telling that if a pixel has a significant value for the three channels, this is because it lies in a location near the observer, or in an artificially illuminated area, and does not need to be restored.}
\end{itemize}
Mathematically, to account for the above observations, we propose to express the compensated red channel $I_{rc}$ at every pixel location $(x)$ as follows:
\begin{equation}
I_{rc}(x)=I_r(x)+\alpha.(\overline{I}_g-\overline{I}_r).(1-I_r(x)).I_g(x)
\end{equation}
where $I_r$, $I_g$ represent the red and green color channels of image $I$, each channel being in the interval [0, 1], after normalization by the upper limit of their dynamic range, while $\overline{I}_r$ and $\overline{I}_g$ denote the mean value of $I_r$ and $I_g$. Each factor in the second term directly results from one of the above observations, and α denotes a constant parameter. In practice, our tests have revealed that a value of $\alpha=1$ is appropriate for various illumination conditions and acquisition settings.\\
To complete our discussion about the severe and color-dependent attenuation of light under water, it is worth noting the works, which reveal and exploit the fact that, in turbid waters or in places with high concentration of plankton, the blue channel may be significantly attenuated due to absorption by organic matter. To address those cases, when blue is strongly attenuated and the compensation of the red channel appears to be insufficient, we propose to also compensate for the blue channel attenuation, i.e. we compute the compensated blue channel $I_bc$ as:
\begin{equation}
I_{bc}(x)=I_b(x)+\alpha.(\overline{I}_g-\overline{I}_b).(1-I_b(x)).I_g(x)
\end{equation}
where $I_b$ , $I_g$ represent the blue and green color channels of image $I$, and $\alpha$ is also set to one. After the red (and optionally the blue) channel attenuation has been compensated, the conventional Gray-World assumption is done to estimate and compensate the illuminant color cast. This white-balancing approach reduces the quantization artifacts introduced by domain stretching (the red regions in the different outputs). The reddish appearance of high intensity regions is also well corrected since the red channel is better balanced.\\
Additionally, this white balancing strategy yields significant improvement in estimating transmission based on the well-known DCP. Estimating the transmission maps based on DCP, using the initial underwater images but also the processed versions with several well-known white balancing approaches (Gray Edge, Shades of Gray, Max RGB and Gray World) yields poor estimates. In contrast, by simply applying DCP on our white balanced
image version we obtain comparable and even better estimates than the specialized underwater techniques of UDCP, MDCP and BP.
\begin{figure}[H]
\centering
\includegraphics[width=15cm,height=5cm]{transmission.png}
\caption[Underwater Transmission Estimation]{Underwater Transmission Estimation}
\label{Underwater Transmission Estimation}
\end{figure}

\chapter{Multi-Scale Fusion}
\justify
Image fusion has shown utility in several applications such as image compositing, multispectral video enhancement, defogging, and HDR imaging. Here, the aim is a simple and fast approach that is able to increase the scene visibility in a wide range of underwater videos and images. This framework builds on a set of inputs and weight maps derived from a single original image. A pair of inputs is introduced to respectively enhance the color contrast and the edge sharpness of the white-balanced image, and the weight maps are defined to preserve the qualities and reject the defaults of those inputs, i.e. to overcome the artifacts induced by the light propagation limitation in underwater medium.\\To derive the inputs from the original image, the CVPR algorithm did assume that the back-scattering component (due to the artificial light that hits the water particles and is then reflected back to the camera) has a reduced influence. This assumption is generally valid for underwater scenes decently illuminated by natural light, but fails in more challenging illumination scenarios. Alternative definition of inputs and weights are taken in order to deal with severley degraded scenes without relying on the optical model.\\ This underwater dehazing technique consists in three main steps: inputs derivation from the white balanced underwater image, weight maps definition, and multi-scale fusion of the inputs and weight maps.

\section{Inputs of the Fusion Process}
Since the color correction is critical in underwater, first the white balancing technique is applied to the original image. This step aims at enhancing the image appearance by discarding unwanted color casts caused by various illuminants. In water deeper than 30 ft, white balancing suffers from noticeable effects since the absorbed colors are difficult to be recovered. As a result, to obtain the \textbf{first} input, a gamma correction of the white balanced image version is performed. Gamma correction aims at correcting the global contrast and is relevant since, in general, white balanced underwater images tend to appear too bright. This correction increases the difference between darker/lighter regions at the cost of a loss of details in the under-/over-exposed regions.\\ To compensate for this loss, a \textbf{second} input is derived that corresponds to a sharpened version of the white balanced image. Therefore, the unsharp masking principle is followed in the sense that a blurred or unsharp (here Gaussian filtered) version of the image is blended with the image to sharpen. The typical formula for unsharp masking defines the sharpened image $S$ as $S=I+\beta(I−G∗I)$, where $I$ is the image to sharpen (in our case the white balanced image), $G∗I$ denotes the Gaussian filtered version of $I$, and $\beta$ is a parameter. In practice, the selection of $\beta$ is not trivial. A small $\beta$ fails to sharpen $I$, but a too large $\beta$ results in over-saturated regions, with brighter highlights and darker shadows. To circumvent this problem, the sharpened image $S$ is defined as follows:
\begin{equation}
S=(I+\Nu{I-G*I})/2
\end{equation}
with $N{.}$ denoting the linear normalization operator, also named histogram stretching in the literature. This operator shifts and scales all the color pixel intensities of an image with a unique shifting and scaling factor defined so that the set of transformed pixel values cover the entire available dynamic range.The sharpening method defined is referred to as normalized unsharp masking process in the following. It has the advantage to not require any parameter tuning, and appears to be effective in terms of sharpening. 
\begin{figure}[H]
\centering
\includegraphics[width=15cm,height=3.5cm]{NUM.png}
\caption[Comparison between traditional Unsharp Masking and normalized Unharp Masking]{Comparison between traditional unsharp masking and normalized Unharp Masking}
\label{Comparison between traditional Unsharp Masking and normalized Unharp Masking}
\end{figure}
This second input primarily helps in reducing the degradation caused by scattering. Since the difference between white balanced image and its Gaussian filtered version is a highpass signal that approximates the opposite of Laplacian, this operation has the inconvenient to magnify the high-frequency noise, thereby generating undesired artifacts in the second input. The multi-scale fusion strategy described in the next section will be in charge of minimizing the transfer of those artifacts to the final blended image.

\section{Weights of the Fusion Process}
The weight maps are used during blending in such a way that pixels with a high weight value are more represented in the final image. They are thus defined based on a number of local image quality or saliency metrics.
\begin{itemize}
\item{\textbf{\textit{Laplacian contrast weight}} ($W_L$) estimates the global contrast by computing the absolute value of a Laplacian filter applied on each input luminance channel. This straightforward indicator was used in different applications such as tone mapping and extending depth of field since it assigns high values to edges and texture. For the underwater dehazing task, however, this weight is not sufficient to recover the contrast, mainly because it can not distinguish much between a ramp and flat regions. So additional and complementary constrast assessment metric is introduced.}
\item{\textbf{\textit{Saliency weight}} ($W_S$) aims at emphasizing the salient objects that lose their prominence in the underwater scene. To measure the saliency level, a saliency estimator is employed. This computationally efficient algorithm has been inspired by the biological concept of center-surround contrast. However, the saliency map tends to favor highlighted areas (regions with high luminance values). To overcome this limitation, an additional weight map based on the observation that saturation decreases in the highlighted regions is introduced.}
\item{\textbf{\textit{Saturation weight}} ($W_{Sat}$) enables the fusion algorithm to adapt to chromatic information by advantaging highly saturated regions. This weight map is simply computed (for each input $I_k$) as the deviation (for every pixel location) between the $R_k$, $G_k$ and $B_k$ color channels and the luminance $L_k$ of the $k^{th}$ input:
\begin{equation}
W_{sat}=\sqrt{1/3*[(R_k-L_k)^2+(G_k-L_k)^2+(B_k-L_k)^2]}
\end{equation}
}
\end{itemize}
\begin{figure}[H]
\centering
\includegraphics[width=15cm,height=5cm]{Weight.png}
\caption[Weight Maps]{Weight Maps}
\label{Weight Maps}
\end{figure}
In practice, for each input, the three weight maps are merged in a single weight map as follows. For each input $k$, an aggregated weight map $W_k$ is first obtained by summing up the three $W_L$ , $W_S$ , and $W_{Sat}$ weight maps. The $K$ aggregated maps are then normalized on a pixel-per-pixel basis, by dividing the weight of each pixel in each map by the sum of the weights of the same pixel over all maps. Formally, the
normalized weight maps $\overline{W}_k$ are computed for each input as:
\begin{equation}
\overline{W}_{sat}=(W_k+\delta)/(\sum_{k=1}^{K}W_k + K*\delta)
\end{equation}
with $\delta$ denoting a small regularization term that ensures that each input contributes to the output. $\delta$ is set to 0.1 in the rest of the paper. The normalized weights of corresponding weights are shown. These three weight maps are used. The exposedness weight map tends to amplify some artifacts, such as ramp edges of our second input, and to reduce the benefit derived from the gamma corrected image in terms of image contrast. Originally, in an exposure fusion context, the exposedness weight map had been introduced to reduce the weight of pixels that are under- or over-exposed. Hence, this weight map assigns large (small) weight to input pixels that are close to (far from) the middle of the image dynamic range. Here since the gamma corrected input tends to exploit the whole dynamic range, the use of the exposedness weight map tends to penalize it in favor of the sharpened image, thereby inducing some sharpening artifacts and missing some contrast enhancements.

\section{Naive Fusion Process}
Given the normalized weight maps, the reconstructed image $R(x)$ could typically be obtained by fusing the defined inputs with the weight measures at every pixel location $(x)$:
\begin{equation}
R(x)=\sum_{k=1}^{K}\overline(W)_k(x)*I_k(x)
\end{equation}
where $I_k$ denotes the input ($k$ is the index of the inputs $K=2$ in our case) that is weighted by the normalized weight maps $\overline{W}_k$. In practice, the naive approach introduces undesirable halos. A common solution to overcome this limitation is to employ multi-scale linear, or non-linear filters.

\section{Multi-Scale Fusion Process}
The multi-scale decomposition is based on Laplacian pyramid. The pyramid representation decomposes an image into a sum of bandpass images. In practice, each level of the pyramid does filter the input image using a low-pass Gaussian kernel $G$, and decimates the filtered image by a factor of 2 in both directions. It then subtracts from the input an up-sampled version of the low-pass image, thereby approximating the (inverse of the) Laplacian, and uses the decimated low-pass image as the input for the subsequent level of the pyramid. Formally, using $G_l$ to denote a sequence of $l$ low-pass filtering and decimation, followed by $l$ up-sampling operations, we define the $N$ levels $L_l$ of the pyramid as follows:
\begin{equation}
I(x) & = I(x)-G_1{I(x)}+G_1{I(x)} \triangleq L_1{I(x)}+G_1{I(x)}
& = L_1{I(x)}+G_1{I(x)}-G_2{I(x)}+G_2{I(x)}
& = L_1{I(x)}+L_2{I(x)}+G_2{I(x)}
& = ...
& = \sum_{l=1}^{N}L_l{I(x)}
\end{equation}
In this equation, $L_l$ and $G_l$ represent the $l^{th}$ level of the Laplacian and Gaussian pyramid, respectively. To write the equation, all those images have been up-sampled to the original image dimension. However, in an efficient implementation, each level $l$ of the pyramid is manipulated at native subsampled resolution. Following the traditional multi-scale fusion strategy, each source input $I_k$ is decomposed into a Laplacian pyramid while the normalized weight maps $\overline{W}_k$ are decomposed using a Gaussian pyramid. Both pyramids have the same number of levels, and the mixing of the Laplacian inputs with the Gaussian normalized weights is performed independently at each level $l$:
\begin{equation}
R_l(x)=\sum_{k=1}^{K}G_l{\overline(W)_k(x)}*L_1{I_k(x)}
\end{equation}
where $l$ denotes the pyramid levels and $k$ refers to the number of input images. In practice, the number of levels $N$ depends on the image size, and has a direct impact on the visual quality of the blended image. The dehazed output is obtained by summing the fused contribution of all levels, after appropriate upsampling.
\begin{figure}[H]
\centering
\includegraphics[width=15cm,height=5cm]{Dehaze.png}
\caption[Overview of Dehazing Schemes]{Overview of Dehazing Schemes}
\label{Overview of Dehazing Schemes}
\end{figure}
By independently employing a fusion process at every scale level, the potential artifacts due to the sharp transitions of the weight maps are minimized. Multi-scale fusion is motivated by the human visual system, which is very sensitive to sharp transitions appearing in smooth image patterns, while being much less sensitive to variations/artifacts occurring on edges and textures (masking phenomenon). This single- scale approximation should definitely be encouraged when complexity is an issue, since it also turns the multiresolution process into a spatially localized procedure.

\chapter{Results and Discussion}
This dehazing technique is compared with the existing specialized underwater restoration/enhancement techniques and the utility of this approach for applications such as segmentation and keypoint matching is proved.
\section{Underwater White Balancing Evaluation}
Since in general the color is captured differently by various cameras,  white balancing approach described in is robust to the camera settings.

\section{Synthesis of Quantum dots}
There are many methods or techniques used in fabrication or synthesis of quantum dots that can be classified as:
\begin{itemize}
\item{Top-down method}
\item{Bottom-up method}
\end{itemize}
\subsection*{Top-down method}
In this method large pieces of the material are carved to the desired nanostructure. One such method is Electron-beam Lithography. In electron beam lithography electron beam system is used to etch well defined patterns on a bulk semiconductor. Then semiconductor layers are grown according to a well- established protocol in micro-technology. 
\begin{figure}[H]
\centering
\includegraphics[width=12cm,height=10cm]{litho}
\caption[Electron Beam Lithography]{Electron Beam Lithography \cite{syn}}
\label{Electron Beam Lithography}
\end{figure}

\subsection*{Bottom-up method}
Bottom-up method is also called self-assembly growth. Molecular Beam Epitaxy (MBE) and Metal Organic Chemical Vapor Deposition (MOCVD) are widely used in the growth of the superlattice with different materials of different lattice constants. Semiconducting compound with a smaller lattice constant is grown (deposited atom by atom) on the surface of a compound with a larger lattice constant. The relaxation of the grown layer after specific growth thickness due to lattice mismatch results in nucleation of islands of random shapes and controllable size. This growth mode is known as Stranski-Krastanov growth. MBE method is slow and expensive. However, growth control of quantum dots is precise and multi-layers of quantum dots is possible. MOCVD is used in mass production of sample wafers and in contrast to MBE the growth of crystals is by chemical reaction and not physical deposition. In this approach high vacuum and temperature are required.
\begin{figure}[H]
\centering
\includegraphics[width=12cm,height=8cm]{beam}
\caption[Molecular beam Epitaxy]{Molecular beam Epitaxy \cite{syn}}
\label{Molecular beam Epitaxy}
\end{figure}

\chapter{Quantum dot Solar cell}
In Quantum dot solar cell the tunable bandgap property of quantum dots is used to increase the efficiency of solar cells.
\section{Intermediate Band Quantum dot Solar cell}
\subsection{Structure}
The intermediate band (IB) solar cell has an allowed electron energy band within the bandgap in order to obtain current from sub-bandgap photons. Provided the electron in the IB are characterized by a Quasi Fermi level (QFL) that is independent of those in the conduction band (CB) and in the valence band (VB), the voltage of the cell can be determined by the CB and VB QFL positions. In this way the solar cell can deliver electron at a voltage  that is above the energy of the less energetic photon that generates current. The thermodynamics requires more than one lower energy photons to cooperate in pumping this electron in order to deliver this high voltage. The confined levels of Quantum dots is used as an IB. The attractiveness of this solar cell is that the detailed balance efficiency limit, calculated following the lines of the elegant Shockley and Queisser (SQ) paper, is 63\%, compared with 41\% in the SQ model. \cite{ib} \\
\begin{figure}[H]
\centering
\includegraphics[width=8cm,height=5cm]{simplestruct}
\caption[A typical QDSC structure]{A typical QDSC structure \cite{pf}}
\label{Quantum dots}
\end{figure} 
\subsection{Electron transfer between bands}
Many attempts have been made to increase the efficiency  of solar cells by introducing an impurity energy level in the semiconductor band gap that absorbs additional lower energy photons. \\
Usual semiconductor has valence band and conduction band, but in intermediate band solar cell (IBSC) an additional intermediate band (IB) is also present. The existence of an isolated IB within the fundamental bandgap \(E_G\) of the IB material enables the absorption of low energy photons through transition labeled (1) and (2). As the absorption of high energy photons is still possible through transition (3) the cell is capable of producing extra photocurrent with respect to conventional cell with gap \(E_G\). Very high conversion efficiency can be obtained because this enhanced photocurrent can be extracted without significant degradation of output voltage. The voltage at the contacts is limted by $E_{G}$ as it would be in the case of a conventional cell with that gap and not by the lower absorption thresholds $E_{H}$ and $E_{L}$. \cite{band}\\

\begin{minipage}[t]{8cm}
\flushleft
\begin{figure}[H]
\includegraphics[width=8cm,height=9cm]{ib1}
\caption[Energy levels in IBSC]{Energy levels in IBSC \cite{band}}
\label{Energy levels}
\end{figure}
\end{minipage}

\begin{minipage}[t]{8cm}
\begin{figure}[H]
\flushright
\includegraphics[width=8cm,height=9cm]{band}
\caption[Band diagram of an IBSC]{Band diagram of an IBSC \cite{ib}}
\label{Band Diagram}
\end{figure}
\end{minipage}

\begin{figure}[H]
\centering
\includegraphics[width=8cm,height=8cm]{graph}
\caption[Plot showing quantum efficiency of reference solar cell and Quantum dot solar cell]{Plot showing quantum efficiency of reference solar cell and Quantum dot solar cell \cite{plot}}
\label{Band Diagram}
\end{figure}

\subsection{Diode equivalent circuit model}
The diode equivalent model consists of a diode $D_{VC}$ (Recombination path from the CB to VB), $D_{IC}$(Recombination path from the IB to CB), $D_{VI}$ (Recombination path from the VB to IB),and $JL_{VC}$ 
(current source from VB to CB), $JL_{IC}$ (current source from IB to CB), $JL_{VI}$ (current source from VB to IB), and a series resistance $R_S$, and a shunt resistance $R_{sh}$ respectively. \\ 
\begin{figure}[H]
\centering
\includegraphics[width=12cm,height=8cm]{em}
\caption[Diode equivalent circuit model]{Diode equivalent circuit model \cite{em}}
\label{Diode Equivalent}
\end{figure}
\subsection{Partial filling of IB}
Partial filling of the intermediate band has to be achieved in order to provide strong absorption in transitions from it to both the valence band and the conduction band. The condition of partial filling of the IB is required in order to have empty states for receiving the electron pumped from the valence band (VB) and the electron filled states to provide for the electrons pumped to the conduction band (CB). Partial filling is achieved by n-doping the barrier region so that the electron delivered by the donors fall into the otherwise empty intermediate band states. \cite{pf}\\

\section{Tuned bandgap Solar cell}
\subsection{Structure}
Another alternative to increase the the efficiency of solar cell using quantum dot is to use multiple layers of quantum dots of different size.  The bandgap of the quantum dot changes based on the size of the dot. So, by incorporating quantum dot of different size the efficiency can be enhanced beyond the Shockley-Queisser limit.
In tuned bandgap quantum dot solar cell the topmost layer has the least size (high bandgap) followed by quantum dots of intermediate size and finally quantum dots of large size (least bandgap). This arrangement causes the formation of sub-bandgaps which helps in the absorption of photons of different frequencies. Thus, ensuring  maximum utilization of solar spctrum.
\begin{figure}[H]
\centering
\includegraphics[width=11cm,height=9cm]{tunedqd}
\caption[Tuned bandgap Quantum dot Solar cell]{Tuned bandgap Quantum dot Solar cell \cite{multi}}
\label{Tuned bandgap Quantum dot Solar cell}
\end{figure}
\subsection{Multiple Exciton Generation(MEG)}
QD solar cells exploit the material quantum efficiency to increase the charge transport capabilities. Incident photons result in multiple exciton generation (MEG) due to impact ionization.
Unlike bulk semiconductors where reduced impact ionization occurs due to faster electron-phonon relaxation times, quantum dots have high impact ionization rates compared to the carrier relaxation time resulting in MEG and enhanced photocurrent.\\
A photon with energy $E>2E_{G}$ excites an electron to the conduction band due to impact ionization. Since quantum dots have discrete energy levels, the excess energy can be used to excite an electron from the valence band to the conduction band.\\ 
\begin{figure}[H]
\centering
\includegraphics[width=9cm,height=8cm]{meg}
\caption[Multiple Exciton Generation(MEG)]{Multiple Exciton Generation(MEG)\cite{meg}}
\label{Tuned bandgap Quantum dot Solar cell}
\end{figure}
\pagebreak
\chapter{Efficiency Deteriorating effects}
Theoretically, we can obtain efficiency upto 66\% using quantum dot solar cell (QDSC). But in reality this high efficiency is not obtained because of some internal deteriorating effects in QDSC.    
\section{Carrier escape in Quantum dot solar cell}
We can increase the efficiency of solar cell using quantum dots as an intermediate band. But this is not achieved because of some internal effects. The transition from valence band to intermediate band is strong but the transition from intermediate band to conduction band is weak due to carrier escape. \\

\begin{figure}[H]
\centering
\includegraphics[width=11cm,height=9cm]{carrier}
\caption[Carrier escape in QD-IBSC]{Carrier escape in QD-IBSC \cite{effect}}
\label{Carrier escape}
\end{figure}

Thermal escape and tunneling are the two main mechanisms of carrier escape in quantum dot solar cell.
There are many reasons for carrier escape one among them is the reduced value of $E_{L}$. This gap is limited to about 0.2eV because of the confluence of an increase of the quantum dots gap under strain and the reduction in the effective $E_{G}$ gap caused by the numerous confined holes states and the quasicontinuum of states introduced by the wetting layer. Also, the existence of excited quantum dot confined states and localized energy levels associated with defects makes thermal escape easier and can assist tunneling escape process.\\

Experimentally, the strategy implemented to enlarge the IB-CB gap and reduce thermal escape is the capping of the quantum dot with a thin layer of strain relief layer(SRL) like InAlGaAs. The use of SRL is an effective method to redshift $E_{H}$. This red shift is produced by the increase in the effective height/size of the quantum dots in the presence of SRL and the reduction in the local strain. In addition to this, in order to avoid tunneling we use spacers of sufficient thickness which acts as a barrier to carrier escape. \cite{carrier} \\

\begin{figure}[H]
\centering
\includegraphics[width=10cm,height=3cm]{data}
\caption[Experimental data]{Experimental data \cite{carrier}}
\label{Experimental data}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=13cm,height=9cm]{plot}
\caption[Experimental result showing reduction in carrier escape due to incorporation of spacer]{Experimental result showing reduction in carrier escape due to incorporation of spacer \cite{carrier}}
\label{Reduction in carrier escape}
\end{figure}

\section{Other disadvantages of quantum dot solar cell}
\begin{itemize}
\item{Defects in the shape of the Quantum dots}\\
Defects in the quantum dot layers causes the formation of traps. This results in the accumulation of carriers in the trap. Thus, lowering of the photocurrent. Strain compensation layers used in quantum dot solar cell helps to smooth these defects. 
\item{Toxicity of Quantum dots}\\
Toxicity of quantum dots reduces the use of quantum dot solar cell. Non-toxic quantum dots can be used in replacement of toxic quantum dots.
\end{itemize}

%\addcontentsline{toc}{chapter{Conclusion and future scope}}
\chapter{Conclusion and future scope}
\justify
Applications of Quantum dots in solar cells is a promising and rapidly progressing research avenue in modern nanophotonics. Solar cells based on Quantum dots are treated as third generation photoelectric converters whose efficiency is expected to be rather high, the device being cheaper than first and second generation solar cells. Incorporation of an intermediate level band using quantum dots in solar cells  enhances its efficiency to a maximum of 66\%. The efficiency of Solar cell can also be increased by using quantum dots of different sizes. These solar cells are capable of utilizing more parts of the solar spectrum. This can be practical and sustainable solution to the challenge of meeting the increasing global energy demand.\\
\pagebreak

\addcontentsline{toc}{chapter}{Bibliography}
\begin{thebibliography}{1}
\bibitem{ib} A.Luque, P.G Linares, E. Antolin, I. Ramiro, C.D. Farmer, E. Hernandez, I. Tobias, C.R Stanley, and A. Marti, "Understanding the operation of quantum dot intermediate band solar cells",{\textit{J. Appl. Phys.}}, pp. 044502-1-044502-12, 2012.

\bibitem{pf}Antonio Marti, Lucas Cuadra, and Antonio Luque, "Partial Filling of a Quantum Dot Intermediate Band for Solar cells", {\textit{IEEE. T. Electron. Dev.}}, vol. 48, no. 10, pp. 2394-2399, 2001.


\bibitem{carrier} E. Antolin, A. Marti,  C.D. Farmer, P.G Linares, E. Hernandez, A.M Sanchez, t. Ben, S.I. Melina, C.R. Stanley, and A. Luque, "Reducing carrier escape in the InAs/GaAs quantum dot intermediate band solar cell", {\textit{J. Appl. Phys.}}, pp. 064513-1-064513-7, 2010.

\bibitem{em}A. Ogura, T. Morioka, P. Garcia-Linares, E. Hernandez, I. Ramiro, I. Artacho, E. Antolin, A. Marti, A. Luque, M. Yamaguchi, and Y. Okada, "Modelling of Quantum Dot Solar Cells for Concentrator PV Applications", in {\textit{Conference record of the 37th IEEE Photovoltaic Specialists Conference (PVSC)}}, IEEE, pp.002642-002645, 2011.

\bibitem{band}E. Antolin, A. Marti, P.G Linares, I. Ramiro, E. Hernandez, C.D. Farmer, C.R Stanley, and A.Luque, "Advances in Quantum Dot Intermediate Band Solar Cells", in {\textit{Conference record of the 35th IEEE Photovoltaic Specialists Conference (PVSC)}}, IEEE, pp. 000065-000070, 2010.


\bibitem{photon} Antonio Luque and Antonio Marti, "Increasing the Efficiency of Ideal Solar cell by Photon Induce Transitions at intermediate Levels", {\textit{Phys. Rev. Lett.}}, vol 78, no. 26, pp.5014-5017,1997.


\bibitem{plot} Zerui Zheng1, Haining Ji1, Peng Yu1, and Zhiming Wang1, "Recent Progress Towards Quantum Dot Solar Cells with Enhanced Optical Absorption", {\textit{Nano. Lett}}, pp. 1-8, 2016.

\bibitem{effect} Yushuai Dail, Christopher G. Bailel, Christopher. Kerestesl, David V. Forbesl, and Seth M. Hubbard, "Investigation of Carrier Escape Mechanism in InAs/GaAs Quantum Dot Solar Cells", in {\textit{Conference record of the 38th IEEE Photovoltaic Specialists Conference (PVSC)}}, pp. 000039-000040, 2012. 

\bibitem{} A. Marti, L. Cuadra, and A. Luque, "Quantum dot intermediate band solar cell", in {\textit{Conference record of the 28th IEEE Photovoltaic Specialists Conference (PVSC)}}, pp. 940-943, 2000.

\bibitem{} Hossain M K, Haque M D, "Performance Analysis of Intermediate Band Solar Cell (IBSC)", {\textit{J Material Sci Eng}}, vol. 4, no.6, pp. 1-8, 2015.

\bibitem{solar} {http://www.explodedhome.com/how-solar-panels-work/.}

\bibitem{chara} {http://pveducation.org/pvcdrom/solar-cell-structure.}

\bibitem{gen} {http://cdn.intechopen.com/pdfs-wm/38725.pdf.}

\bibitem{meg} {https://energysciences.nrel.gov/chemical$_$nanoscale.html.}

\bibitem{multi} {http://iopscience.iop.org/journal/0957-4484/labtalk/article/34339}

\bibitem{sq} {https://en.wikipedia.org/wiki/Shockley$%$E2$%$80$%$93Queisser$_$limit}

\bibitem{el} {http://www.sigmaaldrich.com/}

\bibitem{syn} {http://www.intechopen.com/books/solar-cells-new-approaches-and-reviews/quantum-dots-solar-cells}
\end{thebibliography}
\end{document}
